# 면접 8-2일차

## 7. 소켓이란 무엇인가요? + 8. 포트란 무엇인가요?

### 소켓이란?

**인터넷 소켓**(Internet socket, **socket'** 혹은 **network socket** 라고 부르기도 한다)은 네트워크로 연결되어 있는 컴퓨터의 통신의 접점에 위치한 **통신 객체다**. 프로세스가 네트워크로 데이터를 내보내거나 혹은 그 외부로부터 데이터를 받기 위한 실제적인 창구 역할을 한다. 그러므로 프로세스가 데이터를 보내거나 받기 위해서는 반드시 소켓을 열어서 소켓에 데이터를 써보내거나 소켓으로부터 데이터를 읽어들여야 한다.

 

인터넷 소켓은 다음과 같은 요소들로 구성되어 있다.

- 인터넷 프로토콜 (TCP, UDP, raw IP)
- 로컬 IP 주소
- 로컬 포트
- 원격 IP 주소
- 원격 포트



네트워크 프로그래밍은 소켓을 이용하는데, 소위 소켓 프로그래밍이라고 부른다.

요 소캣 프로그래밍을 하기 위해서 몇가지 소캣 함수들을 사용한다.

각 함수마다 각자의 기능이 있다.

대충 네트워크 구성도는 아래 그림과 같이 구성된다.

<img src="https://user-images.githubusercontent.com/101400894/226942670-c5f91fa1-0ac1-439f-b2fc-a4929154c493.png" alt="image" style="zoom:50%;" ALIGN="LEFT"/>



#### 서버 측

1. 수신 소캣을 생성한다. (socket)
2. ip주소와 포트번호를 결정하여 소캣에 적용시킨다. (bind)
3. 클라이언트 요청을 대기하는 상태(listen 상태)로 변경한다. (listen)
4. 서버에 접속한 클라이언트와 통신할 수 있는 새로운 소캣을 생성한다. (accept)
5. 데이터 송수신을 한다. (recv, send)
6. 끝. (close)

 

#### 클라이언트 측

1. 송신 소캣을 생성한다. (socket)
2. 서버에 접속한다. (connect)
3. 데이터를 송수신한다. (recv, send)
4. 끝 (close)



#### 소켓종류

**스트림 (TCP)**

\- 양방향으로 바이트 스트림을 전송, 연결 지향성

\- 오류 수정, 정송처리, 흐름제어 보장

\- 송신된 순서에 따라 중복되지 않게 데이터를 수신 → 오버헤드가 발생

\- 소량의 데이터보다 대량의 데이터 전송에 적합 → TCP를 사용

**데이터그램 (UDP)**

\- 비연결형소켓

\- 데이터의 크기에 제한이 있음

\- 확실하게 전달이 보장되지 않음, 데이터가 손실돼도 오류가 발생하지 않음

\- 실시간 멀티미디어 정보를 처리하기 위해 주로 사용 ex) 전화



📌**HTTP 통신과 SOCKET 통신의 비교**

**HTTP 통신**

\- Client의 요청(Request)이 있을 때만 서버가 응답(Response)하여 해당 정보를 전송하고 곧바로 연결을 종료하는 방식



**HTTP 통신의 특징**

\- Client가 요청을 보내는 경우에만 Server가 응답하는 단방향 통신이다.

\- Server로부터 응답을 받은 후에는 연결이 바로 종료된다. 

\- 실시간 연결이 아니고, 필요한 경우에만 Server로 요청을 보내는 상황에 유용하다.

\- 요청을 보내 Server의 응답을 기다리는 어플리케이션의 개발에 주로 사용된다.



**SOCKET 통신**

\- Server와 Client가 특정 Port를 통해 실시간으로 양방향 통신을 하는 방식



**SOCKET 통신의 특징**

\- Server와 Client가 계속 연결을 유지하는 양방향 통신이다.

\- Server와 Client가 실시간으로 데이터를 주고받는 상황이 필요한 경우에 사용된다.

\- 실시간 동영상 Streaming이나 온라인 게임 등과 같은 경우에 자주 사용된다.



### 포트

- Port 는 물리적 연결이 아님.
- 프로그램이나 서비스에서 **정보를 교환하기 위해 사용되는** **논리적 연결**
- 포트는 컴퓨터 또는 서버에서 **사용될 프로그램이나 서비스를 특정 지어줌.**
  \- Ex. Web page, FTP, Email, Etc..
- 포트는 프로그램이나 서비스를 식별 할 수 있는 고유한 숫자를 가짐.
  \- 0 - 65535 사이
  - 80, 433 - Web pages(HTTP, HTTPS)
  - 21 - FTP(File Transfer Protocol)
  - 25 - Email
- Port는 항상 IP 주소와 연관되어 있음
  \- 네트워크에 연결된 모든 종류의 장치를 노드(Node)라고 하는데, 노드 중에서도 네트워크 주소인 IP 주소가 할당된 것들을 `호스트`라고 함.
  - 이 **호스트의 IP 주소와 포트번호가 합쳐져서 네트워크를 통해 데이터 교환**을 할 수 있음.
    - Ex. 66.94.34.13:21
  - IP 주소는 서버의 위치를 결정지을 수 있고, 포트 번호는 해당 서버에서 사용하고 싶은 서비스 혹은 프로그램을 결정함.
- 대부분의 사람들이 매일 사용하는 포트는 `80`번으로 HTTP(Hypertext Transfer Protocol), 즉 웹페이지의 포트 번호임.
- 만약 우리가 구글 사이트에서 검색을 하고자 `http://wwww.google.com`을 웹 브라우저에 타이핑하면 우리의 호스트는 DNS를 통해 구글 IP 주소(215.114.85.17) 에 `http`의 포트번호인 `80`을 추가하여 `215.114.85.17:80`으로 구글 웹서버에 도착하게 된다. 이렇게 위의 주소가 구글 웹서버에 도착하면 IP 주소는 더 이상 사용되지 않고, 포트 번호만 남아서 구글 웹서버가 80번 포트번호를 확인하고 해당 요청을 웹서비스로 전달한다. 그렇게 웹서비스로 구글 서버에 전달이 되면 우리는 구글 웹페이지를 볼 수 있게 된다.
  \- 이 모든 작업을 사용자는 보지 못하며, 알고 싶다면 `Netstat`을 통해 Network statistics, 즉 현재 네트워크 연결과 포트 활동을 우리 컴퓨터로 알 수 있다.



## 9. 로드밸런서란 무엇인가요? + 10. L4 로드밸런싱과 L7 로드밸런싱의 차이에 대해 말해주세요

### **로드 밸런서(Load Balancer)**

**서버에 가해지는 트래픽을 여러대의 서버에게 균등하게 분산시켜주는 역할**을 하는 것이 로드 밸런서입니다.

서버가 하나일 때 트래픽이 적으면 서버는 무사히 응답을 해줄 것입니다. 하지만 트래픽이 서버 한개로는 감당할 수 없는 양이 되는 순간 서버는 다운될 것이고, 서비스 또한 작동을 멈출 것입니다.

이러한 문제를 해결하기 위해서는 크게 두 가지 방법이 있는데요.

**서버의 인스턴스 성능을 올리는 스케일-업(\*Scale-up\*)** 과 **서버를 여러대로 나눠서 트래픽을 처리하는 스케일-아웃(\*Scale-out\*)** 방식이 있습니다. 오늘 포스팅하는 이 로드 밸런서는 바로 **스케일-아웃** 방식입니다.

그리고 로드 밸런서는 **지속적으로 IP주소가 바뀌기 떄문에 도메인 기반으로 사용해야 한다**는 특징이 있습니다.

 

**로드 밸런싱을 하면 무슨 장점이 있을까요?**

- **비용 절감**
- **무중단 서비스 제공**

 

**주요 기능**

- **NAT**
- 터널링(Tunneling)
  - 인터넷상에서 눈에 보이지 않는 통로를 만들어 통신할 수 있게 해주는 개념
  - 데이터를 캡슐화해 연결된 상호간에만 캡슐화된 패킷을 구별해 캡슐화를 해제할 수 있음
- DSR(Dynamic Source Routing protocol)
  - 로드 밸런서 사용 시 서버에서 클라이언트로 되돌아가는 경우 목적지 주소를 스위치의 IP 주소가 아닌 클라이언트의 IP 주소로 전달해서 네트워크 스위치를 거치지 않고 바로 클라이언트를 찾아가는 개념입니다.

 

**로드 밸런싱 알고리즘**

- 라운드 로빈(Round Robin)
  - 서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식 서버와의 연결이 오래 지속되지 않을 경우 적합하다.
- 가중 라운드 로빈 
  - 각 서버에 가중치를 매기고 가중치가 높은 서버에 요청을 우선적으로 배정하는 방식
  - 서버의 트래픽 처리 능력이 다를 경우 사용
- 최소 연결 방식(Least Connections)
  - 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 트래픽을 배정하는 방식
  - 서버에 들어온 트래픽들이 일정하지 않은 경우에 적합하다.
- IP 해시 방식(Source)
  - 클라이언트의 IP주소를 특정 서버로 매핑하여 요청을 처리하는 방식
  - 사용자가 항상 동일한 서버로 연결된다.



### **로드 밸런싱 종류**

#### **L2**

- Mac주소를 바탕으로 Load Balancing합니다.

#### **L3**

- IP주소를 바탕으로 Load balancing합니다.

#### **L4**

- Transport 계층(전송 계층) 에서 Load Balancing 합니다. (IP와 Port)
- **데이터를 변경/수정 할 수 없습니다.**
- 패킷 레벨에서만 트래픽을 분산하기 때문에 속도가 빠르고 효울이 높습니다.
- 섬세한 라우팅이 불가능하지만 L7로드 밸런서보다 가격이 저렴합니다.
- TCP,UDP

#### **L7**

- Application 계층(응용 계층) 에서 Load Balancing 합니다.
- **포트나 헤더등의 정보를 수정** 할 수 있습니다.
- **패킷 내용을 확인하고 그 내용에 따라 트래픽을 특정 서버에 분산하는 것이 가능**합니다.
- 섬세한 라우팅이 가능하고, 비정상적인 트래픽을 필터링 할 수 있습니다.
- 패킷의 내용을 복호화 하기 때문에 더 많은 비용이 듭니다.
- HTTP(80), HTTPS(443), FTP(21), WebSocket



📌**L4 LB vs L7 LB**

**L4 Load Balance**r는 ***IP, Port*** 를 기준으로 스케줄링 알고리즘을 통해 부하를 분산합니다. 클라이언트에서 로드밸런서(DNS)로 요청을 보냈을 때 최적의 서버로 요청을 전송하고 결과를 클라이언트에게 줍니다. 

 

**L7 Load Balancer**는 L7 위에서 동작하기 때문에 IP, Port 이외에도 ***URI, Payload, Http Header, Cookie\*** 등의 내용을 기준으로 부하를 분산합니다. 그래서 콘텐츠 기반 스위칭이라고도 합니다. L4 Load Balancer는 단지 부하를 분산시키는 것이라면, L7 Load Balancer는 요청의 세부적인 사항을 두고 결제만 담당하는 서버, 회원가입만을 담당하는 서버 등으로 **분리해서 가볍고 작은 단위로 여러 개의 서비스를 운영하고 요청을 각각의 서버에 분산할 수 있는 것**입니다. 또한, L7 Load Balancer는 L4 Load Balancer와 다르게 데이터를 분석해서 처리가 가능하기 때문에 악의적이거나 비 정상적인 콘텐츠를 감지해 보안 지점을 구축할 수도 있는 장점이 있고, 그 만큼 자원 소모가 크다는 단점이 있습니다.

 



![img](https://blog.kakaocdn.net/dn/ck0dNZ/btrEKUM6v3V/timcEvbT0Cq1iDeL45m650/img.png)



 

 

 



## **타겟 그룹(Target Group)**

타겟그룹이란 EC2인스턴스를 **오토스케일링 할 수 있는 단위**로 사용됩니다.

각각의 타겟그룹에 있는 인스턴스들은 정의된 **Health Checks(상태 확인)**를 수행하게됩니다. 

 

## **Auto Scailing**

오토 스케일링은 미리 정의한 용량 정책에 따라 **EC2 인스턴스의 용량을 확대하거나 축소**할 수 있습니다. EC2와 오토 스케일링을 결합해 **고가용성 아키텍처를 구현**할 수 있으며, 언제든 **원하는 수만큼의 인스턴스를 운용**할 수 있습니다.

서버의 과부하, 장애 등과 같이 서비스 불능 상황 발생시 자동으로 서버를 복제하여 서버 대수를 늘려주는 작업을 해주는 AWS 서비스라고 생각하시면 됩니다.

 

** *고가용성: 서버와 네트워크, 프로그램 등의 정보 시스템이 상당히 오랜 기간 동안 지속적으로 정상 운영이 가능한 성질, 보통 고가용성을 위해 2개의 서버를 연결하는 방식을 사용* **

 

## **Health Checks(상태 확인)**

로드밸런서에는 **Health Checks**를 할 수 있습니다. **Health Checks**는 **타겟그룹에 원하는 경로와 포트를 설정하여 HTTP 응답이 정상적으로 오는지 확인**하고, 오지 않는다면 **비정상 상태의 인스턴스를 제외한 다른 인스턴스로만 트래픽을 분산**합니다.

- InService (정상적으로 응답)
- OurOfService (응답 실패)

 

 

## **ELB(Elastic Load Balancer)**

AWS에 정의되있는 ELB입니다.

Elastic Load Balancing은 둘 이상의 가용 영역에서 EC2 인스턴스, 컨테이너, IP 주소 등 여러 대상에 걸쳐 수신되는 트래픽을 자동으로 분산합니다. 등록된 대상의 상태를 모니터링하면서 상태가 양호한 대상으로만 트래픽을 라우팅합니다. Elastic Load Balancing은 수신 트래픽이 시간이 지남에 따라로드 밸런서를 확장합니다.

로드 밸런서는 클라이언트에서 오는 트래픽을 허용하고, 하나 이상의 가용 영역에서 등록된 대상(예: EC2 인스턴스)으로 요청을 라우팅합니다. 또한, 로드 밸런서는 등록된 대상의 상태를 모니터링하고 정상 대상으로만 트래픽이 라우팅되도록 합니다. 로드 밸런서가 비정상 대상을 감지하면, 해당 대상으로 트래픽 라우팅을 중단합니다. 그런 다음 대상이 다시 정상으로 감지되면 트래픽을 해당 대상으로 다시 라우팅합니다.

하나 이상의 리스너를 지정하여 들어오는 트래픽을 허용하도록 로드 밸런서를 구성합니다. 리스너는 연결 요청을 확인하는 프로세스입니다. 클라이언트와 로드 밸런서 간의 연결을 위한 프로토콜 및 포트 번호로 구성됩니다. 마찬가지로 로드 밸런서와 대상 간의 연결을 위한 프로토콜 및 포트 번호로 구성됩니다.

**- AWS 사용 설명서 -**

ELB의 경우 **네트워크 레이어 4와 네트워크 레이어7에 대한 부하를 제어**할 수 있습니다. 그리고 **서버의 기본주소가 바뀌면 로드밸런서를 새로 생성해야하며 하나의 주소에 하나의 타겟그룹으로 보내게** 됩니다. 따라서 타겟그룹이 많아질수록 더 많은 수의 로드밸런서가 필요하고 비용도 그만큼 더 들아가게 됩니다.

 

## **ALB(Application Load Balancer)**

AWS에 정의되있는 ALB입니다.

Application Load Balancer는 개방형 시스템 간 상호 연결(OSI) 모델의 일곱 번째 계층인 애플리케이션 계층에서 작동합니다. 로드 밸런서는 요청을 받으면 우선 순위에 따라 리스너 규칙을 평가하여 적용할 규칙을 결정한 다음, 규칙 작업의 대상 그룹에서 대상을 선택합니다. 애플리케이션 트래픽의 콘텐츠를 기반으로 다른 대상 그룹에 요청을 라우팅하도록 리스너 규칙을 구성할 수 있습니다. 대상이 여러 개의 대상 그룹에 등록이 된 경우에도 각 대상 그룹에 대해 독립적으로 라우팅이 수행됩니다. 대상 그룹 레벨에서 사용되는 라우팅 알고리즘을 구성할 수 있습니다. 기본 라우팅 알고리즘은 라운드 로빈입니다. 그 대신 최소 미해결 요청 라우팅 알고리즘을 지정할 수 있습니다

리스너는 구성한 프로토콜 및 포트를 사용하여 클라이언트의 연결 요청을 확인합니다. 리스너에 대해 정의한 규칙에 따라 로드 밸런서가 등록된 대상으로 요청을 라우팅하는 방법이 결정됩니다. 각 규칙은 우선 순위, 하나 이상의 작업, 하나 이상의 조건으로 구성됩니다. 규칙에 대한 조건이 충족되면 작업이 수행됩니다. 각 리스너에 대한 기본 규칙을 정의해야 하며, 필요에 따라 추가 규칙을 정의할 수 있습니다.

각 대상 그룹은 지정한 프로토콜과 포트 번호를 사용하여 EC2 인스턴스 같은 하나 이상의 등록된 대상으로 요청을 라우팅합니다. 여러 대상 그룹에 대상을 등록할 수 있습니다. 대상 그룹 기준으로 상태 확인을 구성할 수 있습니다. 로드 밸런서의 리스너 규칙에서 지정한 대상 그룹에 등록된 모든 대상에서 상태 검사가 수행됩니다.

 

**- AWS 사용 설명서 -**

ALB의 경우는 **네트워크 레이어7의 프로토콜에 대한 부하만 처리**할 수 있습니다. ELB와 다르게 **경로나 포트등에 따라 다른 타겟그룹으로 맵핑**할 수 있습니다. **포트 단위로 연결**해줄 수 있기 떄문에 도커에서 유용하게 작동할 수 있고 하나의 대상그룹에 더 많은 컨테이너를 넣을 수 있어 비용을 최적화할 수 있습니다. **EC2 인스턴스, AWS 람다, IP로도 연결이 가능하고 특정한 요청에 대해서는 서버없이 응답메세지를 작성**할 수 있습니다. 

 

ALB에는 리스너를 포트와 프로토콜별로 분기처리할 수 있습니다. 하단에 있는 룰은 패스별 혹은 AWS_ARN별로 다른 분기를 처리할 수 있습니다.

하지만 ALB는 IP가 끊임없이 변화하기 때문에 ALB의 Public IP를 목적지로 삼아 접근 제어(ACL)를 실시하는 네트워크 장비에겐 매우 난감할 수도 있습니다.

 

## **NLB(Network Load Balancer)**

AWS에 정이되있는 NLB입니다.

Network Load Balancer는 오픈 시스템 상호 연결(OSI) 모델의 네 번째 계층에서 작동합니다. 초당 수백만 개의 요청을 처리할 수 있습니다. 로드 밸런서가 연결 요청을 받으면 기본 규칙의 대상 그룹에서 대상을 선택합니다. 리스너 구성에 지정된 포트에서 선택한 대상에 대한 TCP 연결을 열려고 시도합니다.

**- AWS 사용 설명서 -**

NLB는 L4 로드 밸런싱을 하는 로드 밸런서 입니다. L4 로드 밸런싱이기 떄문에 TCP와 UDP에 대한 트래픽을 처리할 수 있고, TLS(SSL Offload)까지 가능한 로드밸런서입니다. NLB는 사용자와 인스턴스간의 논리적인 연결이 생성될 수 있도록 돕습니다. 부하분산을 함과 동시에 사용자와 인스턴스의 커넥션을 생성하도록 돕고 자신 또한 커넥션을 가지며 관리합니다. 무엇보다 NLB의 가장 큰 특징은 ALB와 다르게 고정 IP를 갖는다는 것입니다. Private IP뿐만 아니라 Public IP까지 고정된 IP로 제공합니다. 

 

 



![img](https://blog.kakaocdn.net/dn/nCnKP/btrfp1RgNyT/FL2jgC9GEac2lztYOvCqh0/img.png)



 

## 11. 프로세스와 스레드의 차이에 대해 말해주세요 + 12. 멀티스레딩에서 한 스레드에서 기존 작업을 중단하고 다른 스레드에서 새로운 작업을 처리한 다음 다시 원래 작업을 하려할때 어떻게 정보를 기억하나요?



### **프로세스와 스레드의 차이점은?**

프로그램 : **파일이 저장 장치에 저장되어 있지만 메모리에는 올라가 있지 않은 정적인 상태**(아직 실행되지 않은 파일 그 자체)

+ **메모리에 올라가 있지 않은:** 아직 운영체제가 프로그램에게 독립적인 메모리 공간을 할당해주지 않았다는 뜻이다. 모든 프로그램은 운영체제가 실행되기 위한 메모리 공간을 할당해 줘야 실행될 수 있다.
+ **정적인 상태:** 정적(靜的)이라는 단어 그대로, 움직이지 않는 상태라는 뜻이다. 한 마디로 아직 실행되지 않고 가만히 있다는 뜻이다.



**실행 파일(프로그램)에게 프로그램을 실행**(프로그램 => 프로세스)



프로세스 : 운영체제로부터 자원을 할당받은 **작업**의 단위. (해당 파일은 컴퓨터 메모리에 올라가게 되고, 이 상태를 **동적(動的)인 상태**라고 하며 이 상태의 프로그램을 **프로세스**)

+ **운영체제 관점에서는 프로세스가 최소 작업 단위**

+ **프로세스 = 코드 + DATA + Stack + Heap(OS로부터 자원을 할당받음)**
+ 프로세스는 서로 독립적인 메모리공간을 할당받기 때문에 한 프로세스가 강제종료 되어도 타 프로세스에 영향 x



스레드 : **프로세스 안에서 실행되는 흐름 단위**(프로세스가 할당받은 자원을 이용하는 **실행 흐름**의 단위.)

+ **CPU 입장에서의 최소 작업 단위**

+ 프로세스의 코드에 정의된 절차에 따라 실행되는 특정한 수행 경로다.
+ Stack 영역만 할당받고 나머지(코드 + DATA+ Heap)는 공유
+ 나머지 영역은 공유하기에 강제종료 발생시 같은 프로세스 내의 타 스레드 모두가 종료



프로세스는 최소 하나의 스레드를 보유하고 있으며, 각각 별도의 주소공간을 독립적으로 할당 받는다.(code, heap, stack)

**스레드는 이중에 stack만 따로 할당받고 나머지 영역은 스레드끼리 서로 공유**한다.

 

**요약**

프로세스 : 자신만의 고유 공간과 자원을 할당받아 사용

스레드 : 다른 스레드와 공간과 자원을 공유(stack 영역 공유)하면서 사용



### 멀티태스킹

>  하나의 운영 체제 안에서 여러 프로세스가 실행되는 것



### 멀티스레드

>  하나의 프로세스가 여러 작업을 여러 스레드를 사용하여 동시에 처리하는 것을 의미



**멀티스레드의 장점**

1. Context-Switching할 때 공유하고 있는 메모리만큼의 메모리 자원을 아낄 수 있다.
2. 스레드는 프로세스 내의 Stack 영역을 제외한 모든 메모리를 공유하기 때문에 통신의 부담이 적어서 응답 시간이 빠르다.
   + **프로세스를 생성하거나 Context switching 하는 작업은 너무 무겁고 잦으면 성능 저하가 발생하는데, 스레드를 생성하거나 switching 하는 것은 그에 비해 가볍다.** 

**멀티스레드의 단점**

1. 스레드 하나가 프로세스 내 자원을 망쳐버린다면 모든 프로세스가 종료될 수 있다.
2. 자원을 공유하기 때문에 필연적으로 **동기화 문제**가 발생할 수밖에 없다.



#### **프로세서(CPU), 멀티 프로세스을 가능케 하는 PCB(process control block)와 Context Switching**

 

프로세스가 **동작**될 수 있도록 하는 하드웨어 = **cpu**

 

\* **동작** : 프로그램의 자원들이 실행되기 위해 메모리에 올라오고, **실행되어야 할 코드의 메모리 주소를 cpu의 레지스터로 올리는 것**

 

프로세서(cpu)는 한 순간에 하나의 프로세스만 실행할 수 있다. 

그러나 우리는 여러 프로세스가 동작하고 있는 것을 확인할 수 있다. 이를 **멀티프로세싱**이라고 한다.



![img](https://blog.kakaocdn.net/dn/ch7szf/btqVddRAGRq/FzP32i6K6BbZ63lGptD7d1/img.png)



 

이런 동작이 가능한 것은,

**OS가 매우 짧은 시간에** **프로세스를** **PCB(Process Control Block)에 담긴 정보를 참고하면서** **교체(스위칭)**하고 있기 때문에 여러 작업이 실행되고 있는 것처럼 느낄 뿐. 이를 멀티프로세싱이라고 부른다.

 

다시, 짧은 순간에 여러 프로세스를 교체해가면서 실행하기 위해서는 프로세스의 상태와 프로세스를 제어하기 위한 정보 모음(PCB)를 알아야 한다.

 

 

 

**- \**PCB(Process Control Block)\****

 

**프로세스를 컨트롤하기 위한 정보**이다.

 

PID(process id), **프로세스 상태**, **다음에 실행할 명령어의 주소**, 이전에 작업하던 내용, **CPU 스케쥴링 정보**, 프로세스의 주소 공간 등이 담겨 있다. 이를 싸잡아서 **Context**라고 부른다.

 

각각의 내용들은 깊게 공부할 가치가 있지만, 아무래도 프로그래머로서 중요시해야할 부분은 **프로세스 상태와 스케쥴링 정보**이다.



**- 프로세스 상태**

 

OS가 각 프로세스들을 스위칭하면서 작업하면서 프로세스는 아래의 표와 같은 상태 변화를 겪게 된다.

프로세스가 실행되면 메모리에 적재되면서 Ready 상태.

스케쥴러에 의해 실행되면 Running.
Running 도중 프로그램이 I/O작업을 만나게 되면 Block된 상태가 된다.

![img](https://blog.kakaocdn.net/dn/bbw9UV/btqVdNE7AID/3LCrsoKqeSKUD7TQBkHU6k/img.png)



 **컨텍스트 스위칭**은 아래와 같은 작업을 수행한다 (넘버는 실행 순서와는 관계 없음)

 

1. 현재 실행 중인 프로세스 혹은 스레드의 context 백업 (가령, CPU 레지스터 값들, 어디까지 실행됐는지 등)

2. CPU 캐시를 비움(flush) (CPU 마다 L1, L2 cache에 대한 동작이 다를 수 있음, 심지어 안 비울 수도 있음)

3. TLB(table lookaside buffer)를 비움

4. MMU(memory management unit)를 변경



1번 동작시 프로세스는 PCB, 쓰레드는 TCB 백업

📌**PCB**는 Process ID와 상태, 우선순위, 메모리 정보 등을 저장한다. 멀티스레드가 아닌 멀티프로세스 환경에서는 PCB가 PC와 Register Set 정보도 포함한다. 여기서는 멀티스레드 환경이라 가정한다.

📌**TCB**는 Thread별로 존재하는 자료구조이며, PC와 Register Set(CPU 정보), 그리고 PCB를 가리키는 포인터를 가진다.



여기서 **프로세스 컨텍스트 스위칭**은 1, 2, 3, 4번을 모두 수행하지만 

**스레드 컨텍스트 스위칭**은 1번만 수행한다



그렇기 때문에 **프로세스 컨텍스트 스위칭**을 할 때는 **새로 실행되는 프로세스가 기존에 실행되는 프로세스의 메모리 주소 공간에 침범하면 안 되기 때문에**  

실행 중이었던 프로세스의 상태를 백업할 뿐만 아니라 (1번)

cache도 비워주고 (2번) 

TLB도 비워주고 (3번) 

가상 메모리 주소에서 물리적인 메모리 주소로 변환하는 역할을 하는 MMU 설정도 변경을 해주는 것이다 (4번)

 

특히 비워주는 작업인 2번과 3번이 시간을 꽤 잡아먹는 작업이기 때문에 **프로세스 컨텍스트 스위칭**은 **스레드 컨텍스트 스위칭**에 비해서 오래 걸리는 작업이 된다



**같은 프로세스에 속하는 스레드 간의 컨텍스트 스위칭의 경우에는**  **메모리 주소 공간이 바뀌지 않기 때문에 2, 3, 4번은 수행하지 않아도 돼서** **더 빨리 끝나는 가벼운 작업이 되는 것이다**