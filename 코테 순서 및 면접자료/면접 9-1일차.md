----
## 1. 멀티 프로세스의 장단점을 말해주세요 2. 멀티 스레드의 장단점을 말해주세요

### 실행단위
+ cpu core에서 실행하는 하나의 단위로 프로세스와 스레드를 포괄하는 개념
+ 실행단위는 프로세스 일수도, 스레드일 수도 있음

### 프로세스
+ 하나의 스레드만 가지고 있는 단일 스레드 프로세스

### 동시성
+ 한순간에 여러 가지 일이 아니라, 짧은 전환으로 여러 가지 일을 동시에 처리하는 것처럼 보이는 것.  

### 실행단위 알아보기

#### 1. 프로세스
+ 프로세스는 `코드로 작성된 프로그램이 메모리에 적재되어 사용할 수 있는 상태`가 된 것  
+ `프로그램` 자체는 생명이 없고 프로그램은 보조 기억장치에 존재하며, 실행되기를 기다리는 명령어(코드)와 정적인 데이터의 묶음  
	+ 프로세스는 `실행 중인 프로그램`

#### 2. 스레드
+ 스레드(thread)란 프로세스(process) 내에서 실제로 작업을 수행하는 주체  
+ 모든 프로세스에는 한 개 이상의 스레드가 존재하여 작업을 수행하고, 두 개 이상의 스레드를 가지는 프로세스를 `멀티스레드 프로세스(multi-threaded process)`라 함.

### 멀티 프로세스(Multi process)와 멀티 쓰레드(Multi Thread)

#### 멀티 프로세스
+ 두 개 이상 다수의 프로세서(CPU)가 협력적으로 하나 이상의 작업(Task)을 동시에 처리하는 것(병렬처리)  
+ 각 프로세스 간 메모리 구분이 필요하거나 독립된 주소 공간을 가져야 할 경우 사용

##### **장점**
-   독립된 구조로 안전성이 높음
-   프로세스 중 하나에 문제가 생겨도 다른 프로세스에 영향을 주지 않아, 작업속도가 느려지는 손해 정도는 생기지만 정지되거나 하는 문제는 발생하지 않음
-   여러 개의 프로세스가 처리되어야 할 때 동일한 데이터를 사용하고, 이러한 데이터를 하나의 디스크에 두고 모든 프로세서(`CPU`)가 이를 공유하면 비용적으로 저렴

##### **문제점**
-   독립된 메모리 영역이기 때문에 작업량이 많을수록( `Context Switching`이 자주 일어나서 주소 공간의 공유가 잦을 경우) 오버헤드가 발생하여 성능 저하가 발생
-   `Context Switching` 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 시간이 소모되는 등 오버헤드가 발생

### ❗️**Context Switching**

-   `CPU`는 한 번에 하나의 프로세스만 실행 가능
-   `CPU`에서 여러 프로세스를 돌아가면서 작업을 처리하는 데 이 과정을 `Context Switching`
-   구체적으로, 동작 중인 프로세스가 대기하면서 해당 프로세스의 상태(`Context`)를 보관하고, 대기하고 있던 다음 순서의 프로세스가 동작하면서 이전에 보관했던 프로세스의 상태를 복구하는 작업

#### **멀티 스레드**
-   하나의 프로세스에 여러 스레드로 자원을 공유하며 작업을 나누어 수행
![https://user-images.githubusercontent.com/48986787/126673676-992e01be-01a1-41cc-9a07-f5d6c2f2bba4.png](https://user-images.githubusercontent.com/48986787/126673676-992e01be-01a1-41cc-9a07-f5d6c2f2bba4.png)

### **장점**
-   시스템 자원 소모 감소 (자원의 효율성 증대)
-   프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어 자원을 효율적으로 관리
-   시스템 처리율 향상 (처리 비용 감소)
-   스레드 간 데이터를 주고받는 것이 간단해지고 시스템 자원 소모가 줄어듦
-   스레드 사이 작업량이 적어 `Context Switching`이 빠름(캐시 메모리를 비울 필요가 없음)
-   간단한 통신 방법으로 프로그램 응답시간 단축
-   스레드는 프로세스 내 스택 영역을 제외한 메모리 영역을 공유하기에 통신 비용이 적음
-   힙 영역을 공유하므로 데이터를 주고받을 수 있음

### **문제점**
-   자원을 공유하기에 동기화 문제가 발생 가능(병목현상, 데드락 등)
-   주의 깊은 설계가 필요하고 디버깅이 어려움(불필요 부분까지 동기화하면, 대기시간으로 인해 성능 저하 발생)
-   하나의 스레드에 문제가 생기면 전체 프로세스가 영향을 받음
-   단일 프로세스 시스템의 경우 효과를 기대하기 어려움

## **멀티 스레드 vs 멀티 프로세스**

-   멀티 스레드는 멀티 프로세스보다 작은 메모리 공간을 차지하고 `Context Switching`이 빠른 장점이 있지만, 동기화 문제와 하나의 스레드 장애로 전체 스레드가 종료될 위험을 갖고 있음
-   멀티 프로세스는 하나의 프로세스가 죽더라도 다른 프로세스에 영향을 주지 않아 안정성이 높지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지하는 단점
-   두 방법은 동시에 여러 작업을 수행하는 점에서 동일하지만, 각각의 장단이 있음으로 적용하는 시스템에 따라 적합한 동작 방식을 선택하고 적용




---
## 3. IPC의 3가지 방법을 말해주세요
### IPC
> 프로세서들 간의 의사소통을 하는 것
+ 서로다른 프로세스가 데이터를 주고 받는 것
+ 컴퓨터 내부에서 보다 효율적으로 정보를 주고받기 위한 통신의 일종

❓스레드 간 통신보다 프로세스 간 통신이 어려운 이유
>우리는 fork와 같은 함수로 프로세스를 pthread_create와 같은 함수로 쓰레드를 각각 생성해주는데, 이 과정에서 큰 차이가 존재 
+ **프로세스**는 생성되면서 PC를 포함하여 메모리 공간 등을 복사하여 **별도의 자원을 할당**하지만, **스레드**는 메모리 공간과 **자원을 공유** 
+ 프로세스는 통신할 수 있는 공간이 없기 때문에 통신을 위한 별도의 공간을 만들어주어야 하기 때문에 스레드 간 통신보다 어렵움

### IPC종류
#### **1. 공유 메모리 (Shared Memory)**

![](https://blog.kakaocdn.net/dn/rMpEe/btq3UTK52Yh/fJWtKHZKuq7U95ok6gHVR0/img.png)![](https://blog.kakaocdn.net/dn/cfnwfw/btq3UTxvIY7/qWMFrLlcGiTKcGJiqmAYXk/img.png)

![](https://blog.kakaocdn.net/dn/b3gU5m/btreEmVsnd1/KkCY4xLgg1mY9BOxQ0CJGk/img.png)

-   공유 메모리가 데이터 자체를 공유하도록 지원하는 설비. 프로세스간 **메모리 영역을 공유해서 사용**할 수 있도록 허용한다.
-   프로세스가 공유 메모리 할당을 커널에 요청하면 커널은 해당 프로세스에 메모리 공간을 할당한다. 이후 어떤 프로세스건 해당 메모리 영역에 접근할 수 있다.
    -   공유 메모리가 각 프로세스에게 첨부(attach)하는 방식으로 작동하게 된다.
    -   = 각 프로세스가 메모리 영역에 첨부됨
-   프로세스간 Read, Write를 모두 필요로 할때 사용한다.
-   대량의 정보를 다수의 프로세스에게 배포 가능하다.
-   **중개자 없이** **곧바로 메모리에 접근**할 수 있기 때문에 **모든 IPC 중에서 가장 빠르게 작동할 수 있다**.

#### **2. 파이프 (Pipe)**

![](https://blog.kakaocdn.net/dn/5jWEa/btq3UHjr3UU/13YGWcaNR94WKJLJxrLv4k/img.png)

파이프 (출처 : https://jwprogramming.tistory.com/54)

통신을 위한 **메모리 공간(버퍼)을 생성**하여 프로세스가 데이터를 주고 받게끔 한다.

1.  **익명 파이프 (Anonymous PIPE)**
    -   일반적인 파이프
    -   **통신할 프로세스가 명확하게 알 수 있는 경우 사용**.
        -   부모-자식 or 형제 프로세스 간 통신에 사용
        -   **외부 프로세스에서 사용할 수 없다**.
    -   파이프는 두 개의 프로세스를 연결하고, **하나**의 프로세스는 **데이터를 쓰기**만, **다른 하나**는 **데이터를 읽기**만 할 수 있다. 한쪽 방향으로만 통신이 가능한 파이프의 특징때문에 **반이중**(Half-Duplex) **통신**이라고 부르기도 한다.
    -   송/수신을 모두 하기 원한다면 두 개의 파이프를 만들어야 가능
    -   간단하게 사용할 수 있다.
    -   pipe 함수로 생성
    -   **단점**
        -   반이중 통신 → 프로세스가 읽기와 쓰기 통신을 모두 해야한다면, PIPE 두 개를 만들어야 하므로 구현이 복잡해질 수 있다.
        -   전이중 통신을 고려해야될 상황이라면 **낭비**가 심하기 때문에 좋은 선택이 아니다.
2.  **네임드 파이프 (Named PIPE)**
    -   **전혀 모르는 상태의 프로세스들 사이의 통신에 사용**
    -   익명 파이프의 확장된 상태로 **부모 프로세스와 무관한 다른 프로세스도 통신 가능**  
        -   프로세스 **통신을 위해 이름이 있는 파일을 사용**하기 때문에 가능하다.
        -   **FIFO** 라 불리는 특수 파일을 이용해 서로 관련 없는 프로세스 간 통신에 사용한다.
        -   = **외부 프로세스와 통신 가능**
    -   mkfifo or mknod 함수로 생성
    -   **단점**
        -   반이중 통신 → 전이중 통신을 위해서는 익명 파이프처럼 2개를 만들어야 가능하다.

#### **3. 소켓 (Socket)**

![](https://blog.kakaocdn.net/dn/bgu67n/btq3USFpBaF/fRhSqNHooBf4TAqguvr96K/img.png)![](https://blog.kakaocdn.net/dn/tAY6p/btreyeq2QkV/9efin4rKX98skSP9h5sMA0/img.png)

소켓

-   Unix 도메인 소켓 또는 IPC 소켓은 동일한 호스트 운영 체제에서 실행되는 프로세스간 데이터를 교환하기 위한 데이터 통신 엔드 포인트이다.
-   네트워크 소켓 통신을 통해 데이터를 공유한다.
    -   데이터 교환을 위해 양쪽 PC에서 각각 임의의 포트를 정하고 해당 포트 간의 대화를 통해 데이터를 주고받는 방식이다. 
    -   이 때 각각 PC의 PORT를 담당하는 소켓은 각각 하나의 프로세스이다. 
    -   즉 해당 프로세스는 임의의 PORT를 맡아 데이터를 송수신 하는 역할을 진행하는 프로세스인 것 입니다.
    -   각각의 PC에서 프로세스를 통해 타 PC PORT에 연결하라는 명령을 보내게 되면 두 프로세스는 서로 확인과정을 거쳐 연결을 진행하고 연결 후 마치 PIPE와 같이 **1 대 1로 데이터를 주고받는 방식**이다.
-   클라이언트와 서버가 소켓을 통해서 통신하는 구조로, **원격에서 프로세스 간 데이터를 공유**할 때 사용한다.
-   **전이중(Full Duplex, 양방향) 통신**이 가능하다.
-   서버/클라이언트 환경을 구축하는데 용이하다.
-   서버(bind, listen, accept), 클라이언트(connect)
-   중대형 애플리케이션에서 주로 사용한다.

#### **4. 메시지 큐(Message Queue)**

![](https://blog.kakaocdn.net/dn/ohEUB/btrex1ZiCJ1/tMHErdkcGK36PWuA76vq9K/img.png)![](https://blog.kakaocdn.net/dn/bfkFdW/btreCsPwHBQ/j0JQZF55WT3P3T5h6RjXqK/img.png)

메시지 큐

-   **입출력 방식은 Named 파이프**와 동일하다.
-   **다른점**은 
    -   메시지 큐는 파이프처럼 데이터의 흐름이 아니라 **메모리 공간**이다. (메모리를 사용한 PIPE)
    -   PIPE나 FIFO와는 달리, **다수의 프로세스간 메시지를 전달** 할 수 있음
-   사용할 데이터에 **번호**를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다.
-   메시지의 접근을 위해서는 키(key)가 필요하다.

### **5. 메모리 맵(Memory Map)**

![](https://blog.kakaocdn.net/dn/Ejs6H/btreCUkIkO9/vbjFRllp8h5qnuKLA57f21/img.png)

메모리 맵(출처 : https://doitnow-man.tistory.com/110)

-   공유 메모리처럼 메모리를 공유해준다.
-   메모리 맵은 **열린 파일을 메모리에 맵핑시켜서 공유**하는 방식이다. (즉 공유 매개체가 파일+메모리)
-   주로 **파일로** **대용량 데이터를 공유해야 할 때 사용**한다.
-   FILE IO 가 느릴 때 사용하면 좋다.
-   대부분 운영 체제에서는 프로세스를 실행할 때 실행 파일의 각 세그먼트를 메모리에 사상하기 위해 메모리 맵 파일을 이용한다.
-   메모리 맵 파일은 파일의 크기를 바꿀 수는 없으며 메모리 맵 파일을 사용하기 이전, 또는 이후에만 파일의 크기를 바꿀 수 있다.

### **6. RPC(Remote Procedure Call)**

-   RPC 방법은 분산 네트워크 망에서 많이 사용되는 방식이다.
-   별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게하는 프로세스 간 통신 기술이다. 다시 말해, 원격 프로시저 호출을 이용하면 프로그래머는 함수가 실행 프로그램에 로컬 위치에 있든 원격 위치에 있든 동일한 코드를 이용할 수 있다.
-   해당 방법은 분리된 PC에 저장된 데이터를 마치 내 PC에 존재하는 것처럼 데이터를 가져와 사용하는 통신방법이다.
    -   스텁(stub)을 통해서 마치 자신의 디스크에 존재하는 것 처럼 착각을 일으켜 사용하는 방식이다.
    -   스텁 : 리눅스에서 공유 라이브러리의 일부분 중 하나
    -   프로시저 : 루틴, 서브루틴, 함수와 같은 뜻으로 사용되며 하나의 프로시저는 특정 작업을 수행하기 위한 프로그램의 일부이다. 또는 어떤 행동을 수행하기 위한 일련의 작업 순서를 말한다.

이러한 IPC 통신에서 프로세스 간 데이터를 동기화하고 보호하기 위해 **세마포어**와 **뮤텍스**를 사용한다. (공유된 자원에 한번에 하나의 프로세스만 접근시킬 때)

#### 세마포어(Semaphore)

-   위의 다른 IPC 설비들이 대부분 프로세스간 메시지 전송을 목적으로 하는 것에 반해, 세마포어는 프로세스간 데이터를 동기화하고 보호하는데 목적을 둔다.
-   **공유된 자원에** 여러개의 프로세스가 동시에 접근하면 안되며, **한번에 하나의 프로세스만 접근 가능하도록 할 때 사용**된다.



---
## 4. 프로세스를 구성하는 저장공간 중 스택과 힙 중 무엇이 더 빠른가요?

스택과 힙은 각각 다른 용도로 사용되며, 속도 측면에서 일반적으로는 스택이 더 빠릅니다.

스택은 **함수 호출 및 로컬 변수와 같은 작은 데이터 구조를 저장하는 데 사용**됩니다. 스택은 LIFO(Last-In-First-Out) 구조로 데이터를 저장하며, 가장 **최근에 저장된 데이터가 가장 먼저 제거**됩니다. 스택은 연속된 메모리 블록을 사용하므로 데이터에 빠르게 액세스할 수 있습니다. 또한 스택 프레임의 크기는 컴파일 타임에 이미 결정되어 있으므로 메모리 할당과 해제가 빠르게 이루어집니다.

반면에, 힙은 **동적으로 할당되는 데이터를 저장하는 데 사용**됩니다. 힙은 데이터를 저장하는 데 불연속적인 메모리 공간을 사용하므로, 데이터에 액세스하려면 포인터를 따라가야 합니다. 또한 **힙은 메모리 할당 및 해제 과정에서 오버헤드가 발생**할 수 있습니다.

따라서, 스택은 힙보다 더 빠르게 데이터에 액세스할 수 있지만, 스택의 크기는 고정되어 있으므로 큰 데이터 구조를 저장하기에는 적합하지 않습니다. 대신에, 힙은 동적으로 크기가 조정되므로 대규모 데이터 구조를 저장하는 데 적합합니다.


---
## 5. 선점 스케줄링과 비선점 스케줄링 기법을 각각 하나씩 말해주세요
### 스케줄링
+ 프로세스가 작업을 수행하려면 스케줄러로부터 cpu를 할당
+ 할당을 받는 건 순서에 의해 받을 수 있고, 처리하게 되는 시간을 배정
+ 할당 작업은 운영체제에서 구현이 되며 프로세스에게 효율적으로 자원을 할당하기 위한 정책
+ **어떻게 프로세스들이 CPU를 효율적으로 사용하게 할 것인가**

### 선점 스케줄링 (preemptive scheduling)
>한 프로세스가 cpu를 할당받아서 실행하고 있을 때 다른 프로세스가 cpu를 사용하고 있는 프로세스를 중지시키고 cpu를 차지할 수 있는 스케줄링 기법을 선점 스케줄링 기법
+ 우선순위가 높은 프로세스를 먼저 수행할 때 유리하고 빠른 응답 시간을 요구하는 대화식 시분할 시스템에 유용
+ 많은 오버헤드(overhead)를 초래함
+ A라는 프로세스가 cpu를 사용하고 있을 때 잠시 중지시키고 B를 시키는 상황에 사용됨.
+ 예 )  round robin, SRT, 선점 우선 순위 등의 알고리즘

### 비선점 스케줄링(non-preemptive scheduling)
>이미 사용되는 cpu를 빼았지는 못하고 사용이 끝날 때 까지 기다리는 스케줄링 기법
+ 할당 받은 cpu는 끝날 때 까지 사용함.
+ 응답 시간을 예측할 수 있고 일괄 처리 방식이 적합
+ 모든 프로세스에 요구에 대해 공정
+ 중요도가 높은 작업이 낮은 작업이 기다리는 경우가 발생
+ 예 ) FCFS(first come first service), SJF(shortest job first), 우선 순위, HRN(heighest response next)
-> 높은 우선순위가 먼저 실행되고 낮은 작업이 기다리게 된다.


선점 스케줄링의 경우에는 I/O요청, I/O응답, Interrupt발생, 작업완료 등의 상황에서 스케줄링이 일어날 수 있다. 하지만 비선점 스케줄링의 경우 프로세스가 스스로 CPU를 놓아주는 시점(작업이 완료되는 시점)에만 스케줄링이 일어난다.





1. 선점 스케줄링

**1-1**.SRT(Shortest Remaining Time) 스케줄링: 짧은 시간 순서대로 프로세스를 수행한다. 남은 처리 시간이 더 짧은 프로세스가 Ready 큐에 들어오면 그 프로세스가 바로 선점됨. 아래에 소개할 SJF의 선점 버전이라고 할 수 있다.  

**1-2.** 라운드로빈(Round-Robin)스케줄링: 각 프로세스는 같은 크기의 CPU 시간을 할당 받고 선입선출에 의해 행된다. 할당시간이 너무 크면 선입선출과 다를 바가 없어지고, 너무 작으면 오버헤드가 너무 커진다.  

**1-3**.다단계 큐(Multi-level Queue) 스케줄링: Ready큐를 여러 개 사용하는 기법. 각각의 큐는 자신의 스케줄링 알고리즘을 수행하며, 큐와 큐 사이에도 우선순위를 부여한다.  

**1-4. 다단계 피드백 큐 스케줄링: 다단계 큐와 비슷하나 프로세스들이 큐를 이동할 수 있다.




2. 비선점 스케줄링

**1-1.  HRN(Highest response ratio next)** 스케줄링: 긴 작업과 짧은 작업간의 지나친 불평등을 어느 정도 보완한 기법. 수행시간의 길이와 대기 시간을 모두 고려해 우선순위를 정한다.

**1-2. SJF(Shortest Job First)** 스케줄링: 큐 안에 있는 프로세스 중 수행시간이 짧은 것을 먼저 수행. 평균 대기 시간을 감소시킨다.

1-3. 우선순위(priority) 스케줄링: 프로세스에게 우선순위를 정적, 혹은 동적으로 부여하여 우선순위가 높은 순서대로 처리한다. 동적으로 부여할 경우, 구현이 복잡하고 오버헤드가 많다는 단점이 있으나, 시스템의 응답속도를 증가시킨다.

**1-4.** 기한부(Deadline) 스케줄링: 작업을 명시된 시간이나 기한 내에 완료하도록 계획.

**1-5. FIFO** 스케줄링: 프로세스들은 Ready큐에 도착한 순서대로 CPU를 할당 받는다. 작업 완료 시간을 예측하기 매우 용이하다. 하지만 덜 중요한 작업이 중요한 작업을 기다리게 할 수도 있다.

❓**오버헤드**
어떤 작업을 수행하기 위해 필요한 추가적인 작업 또는 비용(시간)을 말합니다. 컴퓨터 분야에서는 다음과 같은 상황에서 오버헤드가 발생합니다.

1.  시스템 자원 할당: 시스템 자원을 할당하는 데 드는 시간과 비용, 이를 위한 코드 및 데이터 구조 등이 오버헤드의 일부입니다.
    
2.  데이터 전송: 데이터 전송 시에 발생하는 프로토콜 상의 오버헤드나, 전송 시 사용하는 데이터의 압축, 암호화 등도 오버헤드의 일부입니다.
    
3.  자원 관리: 시스템 자원 관리를 위한 프로세스, 쓰레드, 메모리, 파일 시스템 등의 구조, 그리고 이를 위한 락(lock) 등의 구현도 오버헤드의 일부입니다.
    
4.  가상화: 가상머신, 컨테이너, 가상 메모리 등을 사용하는 가상화 기술은, 추가적인 구조와 계산이 필요하여 오버헤드가 발생할 수 있습니다.
    

이러한 오버헤드는 시스템의 성능을 떨어뜨리고, 시스템의 부하를 높일 수 있으며, 최적화 작업 등을 통해 최소화하는 것이 중요


----
## 6. 라운드로빈 스케줄링에 대해 설명해주세요
### RR 스케줄링

![](https://blog.kakaocdn.net/dn/bRxdrW/btq3dald9uM/Lczqm1ZgiiESXOeA6l9uFk/img.jpg)

RR(Round Robin / 라운드 로빈) 스케줄링은 **대화형 시스템에서 사용**되는 선점 스케줄링 방식이다. 이 알고리즘은 **프로세스가 도착한 순서대로 프로세스를 디스패치하지만 정해진 시간 할당량(또는 시간 간격)에 의해 실행을 제한**한다. 즉, **시간 할당량을 매 프로세스에 주고 할당된 시간 안에 완료되지 못한 프로세스는 준비 큐의 맨 뒤에 배치되도록 하여 CPU를 독점하지 않고 공평하게 이용**될 수 있게 한다.

### RR 스케줄링의 예

예를 들어, 아래와 같이 4개의 프로세스가 주어지고 **시간 할당량은 3**으로 가정하자.

```
도착시간     0 1 2 3
프로세스     A B C D
CPU 사이클  6 3 1 4 
```

처음에는 프로세스 A만 도착했으므로 바로 디스패치하여 실행시킨다. 시간 할당량 3이 지날 동안 프로세스 A는 계속 실행 중이고 준비 큐에는 프로세스 B,C,D가 순서대로 도착하여 기다리고 있다. 따라서 RR 스케줄링 알고리즘은 프로세스 A를 준비 큐의 맨 뒤로 배치시키고 다음 차례인 프로세스 B를 디스패치하여 실행시킨다.

시간 할당량 3이 지나는 동안 프로세스 B도 마침 종료를 하게되어 다음 순서인 프로세스 C를 디스패치하여 실행시킨다. 프로세스 C는 1만큼의 시간 만에 종료되어 바로 다음 순서인 프로세스 D를 디스패치하여 실행시킨다.

다시 시간 할당량 3이 지나도 프로세스 D는 종료하지 못하여 RR 스케줄링은 프로세스 D를 준비 큐의 맨 뒤로 배치시키고, 다음 차례인 프로세스 A를 디스패치하여 실행시킨다.

시간 할당량 3이 지나면 A도 종료가 되고, 마지막으로 프로세스 D를 디스패치하여 실행시키면 1만큼 지난 뒤 종료된다. 최종 결과는 아래와 같다.

```
0     3     6   7   10   13  14
|  A  |  B  | C | D |  A  | D |
```

각 프로세스가 준비 큐에 있었던 시간인 대기시간은, 프로세스 A는 3부터 10 사이인 7이 되고, 프로세스 B는 1(도착시간 기준)부터 3 사이인 2로, 프로세스 C는 2부터 6사이인 4, 프로세스 D는 3부터 7사이와 10부터 13 사이이므로 4+3=7이 된다.

그리고 반환시간은 프로세스 A는 13-0=13, 프로세스 B는 6-1=5, 프로세스 C는 7-2=5, 프로세스 D는 14-3=11이다. 아래는 프로세스의 대기시간과 반환시간을 정리한 것이다.

```
프로세스 A B C D
대기시간 7 2 4 7
반환시간 13 5 5 11
```

따라서 평균 대기시간은 (7+2+4+7)/4=5 이고, 평균 반환시간은 (13+5+5+11)/4=8.5가 된다.

### 성능 

RR 스케줄링 알고리즘의 성능은 평균 CPU 소요시간에 대한 시간 간격의 길이에 따라 달라진다. 간격이 너무 큰 경우에는 FCFS 정도로 성능이 낮아질 것이다. 간격이 너무 짧은 경우 잦은 문맥 교환이 작업 수행을 방해하여 오버헤드가 크게 증가할 것이다.

따라서 가장 적절한 시간 간격은 시스템 형태에 달려 있다. 대화형 환경에서 사용자가 간단한 요청을 한 경우라면 시스템은 빠른 응답시간을 요구한다. 하지만 일괄처리 시스템이라면 응답시간은 중요한 것이 아니고 오버헤드가 중요한 요인이 된다.

적절한 시간 간격을 결정하는 데는 일반적인 규칙 두 가지가 있다. 첫째는 80%의 CPU 사이클을 처리할 수 있도록 하는 것이고, 둘째는 한 번의 문맥 교환에 걸리는 시간보다 100배 정도는 길어야 한다. 이런 규칙은 몇몇 시스템에 채택되어 사용되고 있으나 변동 가능하다.


## 7. 뮤텍스와 세마포어의 차이점에 대해 설명해주세요

### 임계구역(Critical Section)이란
> 여러 프로세스 혹은 스레드가 작업을 수행하면서 공유된 자원을 건드리게 될 수 있는데, 이때 프로그램 코드 상에서 공유 자원에 접근하는 부분을 임계 구역이라고 합니다. 

이렇게 임계 구역에 여러 프로세스 및 스레드가 함부로 접근할 수 없도록 관리를 잘 해줘야 하는데, 이를 위해 사용하는 방식에 대표적으로 세마포어와 뮤텍스가 있습니다. 

### 뮤텍스(mutex)
뮤텍스는 Key 에 해당하는 어떤 오브젝트가 있으며 이 오브젝트를 소유한 (쓰레드,프로세스) 만이 공유자원에 접근할 수 있다.

![](https://3553248446-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-M5HOStxvx-Jr0fqZhyW%2F-MH25VklJHGlyU_CCTs3%2F-MH2RPdEsVXjF179oobr%2FMutex-in-OS-Operating-System.png?alt=media&token=274fc9a1-365b-489e-b1c3-a2f8125f24bf)

#### 과정
-   1번 프로세스가 자원을 접근하기 위해 Key를 점유한다.
-   1번 프로세스는 키를 점유했기 때문에 공유 자원을 사용한다.
-   2번 프로세스가 공유 자원을 사용하기를 원한다.
-   2번 프로세스는 키를 점유하기 위해 대기한다.
-   3번 프로세스 또한 공유 자원을 사용하기 위해 2번 프로세스 다음 순번으로 대기한다.
-   1번 프로세스가 공유 자원을 다 사용하고 Key를 반환한다.
-   2번 프로세스는 대기하고 있다가 반환된 Key를 점유하고 공유 자원을 사용한다.

### 세마포어(Semaphore)
공유 리소스에 접근할 수 있는 최대 허용치 만큼 동시 사용자(쓰레드, 프로세스) 접근을 허용하게 한다.

![](https://3553248446-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-M5HOStxvx-Jr0fqZhyW%2F-MH25VklJHGlyU_CCTs3%2F-MH2RRv7KZTokJ2fkHd5%2FCounting-Semaphore-in-OS-Operating-System.png?alt=media&token=c4c209d9-da67-4410-80d2-f5badf35cd8c)

### 과정

-   공유 자원에 대한 최대 허용치를 정의한다. 우선, 3으로 해보겠다.
-   1번 프로세스가 공유 자원에 접근한다. 허용치는 2로 감소하였다.
-   2번 프로세스가 공유 자원에 접근한다. 허용치는 1로 감소하였다.
-   3번 프로세스가 공유 자원에 접근한다. 허용치는 0로 감소하였다.
-   4번 프로세스가 공유 자원에 접근한다. 허용치가 0이므로 대기한다.
-   2번 프로세스가 공유 자원을 다 사용하였다. 허용치는 1로 증가하였다.
-   4번 프로세스는 대기 하다 허용치가 1로 증가되어 공유 자원에 접근한다. 허용치는 다시 0으로 감소하였다.

### 뮤텍스와 세마포어의 차이

-   세마포어는 뮤텍스가 될 수 있지만, 뮤텍스는 세마포어가 될 수 없다.
-   세마포어는 소유할 수 없으며, 뮤텍스는 소유할 수 있고 소유주가 그에 대한 책임을 가진다.
-   세마포어는 동기화 대상이 여러개 일 때 사용하고, 뮤텍스는 동기화 대상이 오로지 하나 일 때 사용된다.세스들의 공유 리소스에 대한 접근을 조율하기 위해 동기화 또는 락을 사용합니다.
	-   즉 뮤텍스 객체를 두 스레드가 동시에 사용할 수 없습니다.   
